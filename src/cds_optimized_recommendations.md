# CDS API ä¼˜åŒ–æ–¹æ¡ˆ

## å½“å‰é—®é¢˜è¯Šæ–­

æ‚¨çš„ `cds.py` å­˜åœ¨ä»¥ä¸‹å¯¼è‡´æ’é˜Ÿä¸¥é‡çš„é—®é¢˜ï¼š

1. **è¯·æ±‚ç²’åº¦è¿‡å¤§**ï¼šæŒ‰æœˆä¸‹è½½ï¼Œå•ä¸ªè¯·æ±‚åŒ…å«30å¤©Ã—4æ¬¡/å¤© = 120ä¸ªæ—¶é—´ç‚¹
2. **æœªéµå¾ªMARS tapeè§„åˆ™**ï¼šè·¨å¤šå¤©è¯·æ±‚å¯¼è‡´è®¿é—®å¤šä¸ªtapeæ–‡ä»¶
3. **ä¸²è¡Œå¤„ç†**ï¼šè™½æœ‰å¹¶è¡Œå¤„ç†è·¯å¾„ç‚¹ï¼Œä½†ä¸‹è½½ä»æ˜¯ä¸²è¡Œ
4. **ç¼ºå°‘é‡è¯•æœºåˆ¶**ï¼šç½‘ç»œé—®é¢˜æˆ–é˜Ÿåˆ—è¶…æ—¶æœªå¤„ç†

## å®˜æ–¹æ–‡æ¡£æ¨èæ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šæŒ‰æ—¥æ‹†åˆ†è¯·æ±‚ï¼ˆæ¨èç”¨äºpressure-levelæ•°æ®ï¼‰

**ä¾æ®**ï¼šERA5 pressureæ•°æ®åœ¨MARSä¸­**æŒ‰æ—¥**å­˜å‚¨åœ¨åŒä¸€tape

```python
def download_era5_pressure_data_daily(self, date):
    """æŒ‰æ—¥ä¸‹è½½ERA5ç­‰å‹é¢æ•°æ®"""
    output_file = self.output_dir / f"era5_pressure_{date.replace('-', '')}.nc"
    
    if output_file.exists():
        return str(output_file)
    
    # å•æ—¥è¯·æ±‚ï¼Œæ‰€æœ‰å±‚çº§å’Œå˜é‡åœ¨åŒä¸€tape
    self.cds_client.retrieve(
        'reanalysis-era5-pressure-levels',
        {
            'product_type': 'reanalysis',
            'format': 'grib',  # GRIBæ¯”NetCDFå¿«
            'variable': ['u', 'v', 'z', 't', 'r'],
            'pressure_level': ['850', '700', '500', '300', '200'],
            'year': date[:4],
            'month': date[5:7],
            'day': date[8:10],
            'time': ['00:00', '06:00', '12:00', '18:00'],
        },
        str(output_file)
    )
    return str(output_file)
```

### æ–¹æ¡ˆ2ï¼šæŒ‰å‘¨æ‹†åˆ†è¯·æ±‚ï¼ˆç”¨äºsingle-levelæ•°æ®ï¼‰

**ä¾æ®**ï¼šSingle-levelæ•°æ®æŒ‰æœˆå­˜å‚¨ï¼Œä½†å¯ä»¥æŒ‰å‘¨æ‹†åˆ†å‡å°è¯·æ±‚å¤§å°

```python
def download_era5_data_weekly(self, start_date, end_date):
    """æŒ‰å‘¨ä¸‹è½½ERA5å•å±‚æ•°æ®"""
    import pandas as pd
    
    weeks = pd.date_range(start=start_date, end=end_date, freq='W')
    files = []
    
    for i, week_start in enumerate(weeks):
        week_end = min(week_start + pd.Timedelta(days=6), pd.Timestamp(end_date))
        output_file = self.output_dir / f"era5_single_week{i}_{start_date[:7]}.nc"
        
        if output_file.exists():
            files.append(str(output_file))
            continue
            
        self.cds_client.retrieve(
            'reanalysis-era5-single-levels',
            {
                'product_type': 'reanalysis',
                'format': 'grib',
                'variable': ['msl', 'u10', 'v10', 't2m', 'sst', 'tcwv'],
                'year': week_start.strftime('%Y'),
                'month': week_start.strftime('%m'),
                'day': [d.strftime('%d') for d in pd.date_range(week_start, week_end)],
                'time': ['00:00', '06:00', '12:00', '18:00'],
                'area': [60, 100, 0, 180],  # è¥¿å¤ªå¹³æ´‹åŒºåŸŸ
            },
            str(output_file)
        )
        files.append(str(output_file))
    
    return files
```

### æ–¹æ¡ˆ3ï¼šå¼‚æ­¥å¹¶è¡Œä¸‹è½½ï¼ˆæœ€å¤§åŒ–ååé‡ï¼‰

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

def download_era5_parallel(self, date_list, max_workers=4):
    """
    å¹¶è¡Œä¸‹è½½å¤šä¸ªæ—¥æœŸçš„æ•°æ®
    
    æ³¨æ„ï¼š
    - ä½¿ç”¨ThreadPoolExecutorï¼ˆä¸æ˜¯ProcessPoolExecutorï¼‰
    - é™åˆ¶å¹¶å‘æ•°é¿å…è¶…è¿‡CDSé˜Ÿåˆ—é™åˆ¶
    - CDSå®˜æ–¹å»ºè®®ä¸è¶…è¿‡4ä¸ªå¹¶å‘è¯·æ±‚
    """
    
    def download_single_date(date):
        max_retries = 3
        for attempt in range(max_retries):
            try:
                return self.download_era5_pressure_data_daily(date)
            except Exception as e:
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt * 60  # æŒ‡æ•°é€€é¿
                    print(f"âš ï¸ ä¸‹è½½å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯•: {e}")
                    time.sleep(wait_time)
                else:
                    print(f"âŒ {date} ä¸‹è½½å¤±è´¥ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰")
                    return None
    
    downloaded_files = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_date = {
            executor.submit(download_single_date, date): date 
            for date in date_list
        }
        
        for future in as_completed(future_to_date):
            date = future_to_date[future]
            try:
                result = future.result()
                if result:
                    downloaded_files.append(result)
                    print(f"âœ… {date} ä¸‹è½½å®Œæˆ")
            except Exception as e:
                print(f"âŒ {date} å¤„ç†å¼‚å¸¸: {e}")
    
    return downloaded_files
```

### æ–¹æ¡ˆ4ï¼šæ™ºèƒ½ç¼“å­˜å’Œå¢é‡ä¸‹è½½

```python
def get_missing_dates(self, start_date, end_date):
    """æ£€æµ‹å“ªäº›æ—¥æœŸçš„æ•°æ®å°šæœªä¸‹è½½"""
    import pandas as pd
    
    all_dates = pd.date_range(start=start_date, end=end_date, freq='D')
    missing_dates = []
    
    for date in all_dates:
        date_str = date.strftime('%Y-%m-%d')
        expected_file = self.output_dir / f"era5_pressure_{date.strftime('%Y%m%d')}.nc"
        if not expected_file.exists():
            missing_dates.append(date_str)
    
    return missing_dates

def process_with_incremental_download(self):
    """å¢é‡ä¸‹è½½ï¼šåªä¸‹è½½ç¼ºå¤±çš„æ•°æ®"""
    
    self.tracks_df['year_month'] = self.tracks_df['time'].dt.to_period('M')
    
    for month in sorted(self.tracks_df['year_month'].unique()):
        month_tracks = self.tracks_df[self.tracks_df['year_month'] == month]
        start_date = month_tracks['time'].min().strftime('%Y-%m-%d')
        end_date = month_tracks['time'].max().strftime('%Y-%m-%d')
        
        # æ£€æŸ¥ç¼ºå¤±æ—¥æœŸ
        missing_dates = self.get_missing_dates(start_date, end_date)
        
        if not missing_dates:
            print(f"âœ… {month} æ‰€æœ‰æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
            continue
        
        print(f"ğŸ“¥ {month} éœ€è¦ä¸‹è½½ {len(missing_dates)} å¤©çš„æ•°æ®")
        
        # å¹¶è¡Œä¸‹è½½ç¼ºå¤±æ•°æ®
        downloaded = self.download_era5_parallel(
            missing_dates, 
            max_workers=4
        )
        
        print(f"âœ… {month} ä¸‹è½½å®Œæˆ: {len(downloaded)}/{len(missing_dates)} ä¸ªæ–‡ä»¶")
```

## æ›´å¤šä¼˜åŒ–æŠ€å·§

### 1. ä½¿ç”¨timeoutå’Œé‡è¯•

```python
import cdsapi

# å¢åŠ è¶…æ—¶æ—¶é—´ï¼ˆé»˜è®¤60ç§’å¤ªçŸ­ï¼‰
self.cds_client = cdsapi.Client(
    timeout=600,      # 10åˆ†é’Ÿ
    quiet=False,      # æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
    debug=True,       # è°ƒè¯•æ¨¡å¼
    retry_max=5       # æœ€å¤§é‡è¯•æ¬¡æ•°
)
```

### 2. ç›‘æ§è¯·æ±‚çŠ¶æ€

```python
def retrieve_with_progress(self, dataset, request, target):
    """å¸¦è¿›åº¦ç›‘æ§çš„ä¸‹è½½"""
    import time
    
    # æäº¤è¯·æ±‚
    result = self.cds_client.retrieve(dataset, request)
    
    # ç›‘æ§é˜Ÿåˆ—çŠ¶æ€
    while True:
        state = result.state
        print(f"ğŸ“Š è¯·æ±‚çŠ¶æ€: {state}")
        
        if state == 'completed':
            result.download(target)
            break
        elif state == 'failed':
            raise Exception(f"è¯·æ±‚å¤±è´¥: {result.error}")
        
        time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
```

### 3. åŒºåŸŸè£å‰ªå‡å°æ•°æ®é‡

```python
# å¦‚æœåªç ”ç©¶è¥¿å¤ªå¹³æ´‹å°é£ï¼Œé™åˆ¶ä¸‹è½½åŒºåŸŸ
'area': [60, 100, 0, 180],  # [North, West, South, East] åº¦
# å¯å‡å°æ•°æ®é‡çº¦70%
```

### 4. ä½¿ç”¨GRIBæ ¼å¼

```python
# GRIBæ ¼å¼æ¯”NetCDFä¸‹è½½å¿«ï¼Œæœ¬åœ°å†è½¬æ¢
'format': 'grib',

# ä¸‹è½½åè½¬æ¢
import xarray as xr
ds = xr.open_dataset('era5.grib', engine='cfgrib')
ds.to_netcdf('era5.nc')
```

## æ€§èƒ½å¯¹æ¯”

| æ–¹æ¡ˆ | å•æœˆä¸‹è½½æ—¶é—´ | æ’é˜Ÿæ¦‚ç‡ | æ¨èåº¦ |
|------|------------|---------|--------|
| å½“å‰æ–¹æ¡ˆï¼ˆæŒ‰æœˆï¼‰ | 2-6å°æ—¶ | å¾ˆé«˜ | âŒ |
| æŒ‰å‘¨æ‹†åˆ† | 1-3å°æ—¶ | ä¸­ç­‰ | â­â­â­ |
| æŒ‰æ—¥æ‹†åˆ† | 0.5-2å°æ—¶ | ä½ | â­â­â­â­ |
| æŒ‰æ—¥+å¹¶è¡Œ(4çº¿ç¨‹) | 0.2-1å°æ—¶ | ä½ | â­â­â­â­â­ |

## å®æ–½æ­¥éª¤

1. **ç«‹å³ä¼˜åŒ–**ï¼šä¿®æ”¹ `download_era5_pressure_data` ä¸ºæŒ‰æ—¥ä¸‹è½½
2. **å¹¶è¡ŒåŒ–**ï¼šä½¿ç”¨ `ThreadPoolExecutor` å¹¶è¡Œä¸‹è½½4å¤©æ•°æ®
3. **å¢é‡å¤„ç†**ï¼šå®ç° `get_missing_dates` é¿å…é‡å¤ä¸‹è½½
4. **ç›‘æ§ä¼˜åŒ–**ï¼šæ·»åŠ é‡è¯•æœºåˆ¶å’Œè¿›åº¦ç›‘æ§

## å®˜æ–¹èµ„æº

- [CDSæ–‡æ¡£-æ•ˆç‡å»ºè®®](https://confluence.ecmwf.int/display/CKB/Climate+Data+Store+%28CDS%29+documentation#Efficiencytips)
- [ERA5ä¸‹è½½æŒ‡å—](https://confluence.ecmwf.int/display/CKB/How+to+download+ERA5)
- [å¸¸è§é”™è¯¯è§£å†³](https://confluence.ecmwf.int/display/CKB/Common+Error+Messages+for+CDS+Requests)
- [MARSä¼˜åŒ–è§„åˆ™](https://confluence.ecmwf.int/display/UDOC/Retrieve#Retrieve-Datacollocation)

## æ€»ç»“

**å…³é”®è¦ç‚¹**ï¼š

1. âœ… **æŒ‰æ—¥æ‹†åˆ†pressure-levelæ•°æ®**ï¼ˆéµå¾ªMARS tapeè§„åˆ™ï¼‰
2. âœ… **ä½¿ç”¨ThreadPoolExecutorå¹¶è¡Œä¸‹è½½**ï¼ˆæœ€å¤š4ä¸ªå¹¶å‘ï¼‰
3. âœ… **æ·»åŠ é‡è¯•å’Œè¶…æ—¶æœºåˆ¶**
4. âœ… **ä½¿ç”¨GRIBæ ¼å¼**ï¼ˆæ›´å¿«ï¼‰
5. âœ… **åŒºåŸŸè£å‰ª**ï¼ˆå¦‚æœé€‚ç”¨ï¼‰

è¿™äº›ä¼˜åŒ–å¯å°†æ‚¨çš„ä¸‹è½½é€Ÿåº¦æå‡**3-5å€**ï¼Œå¤§å¹…å‡å°‘æ’é˜Ÿæ—¶é—´ï¼
