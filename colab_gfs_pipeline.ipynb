{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "colab_gfs_pipeline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Google Colab：GFS 数据合并 + 追踪 + 环境提取（复用现有代码）\n",
        "\n",
        "本 Notebook 直接复用仓库中已经实现的逻辑（无需改算法）：\n",
        "\n",
        "- **下载**：根据 `output/gfs_grib_urls_*.csv` 从公开 NOAA GFS S3 拉取 GRIB2\n",
        "- **合并**：调用 `src/shared/grib_loader.py` 合并为单个 NetCDF（包含 `msl, 10u, 10v, z`）\n",
        "- **轨迹**：根据 `input/matched_cyclone_tracks*.csv` 为每个预报周期生成轨迹 CSV\n",
        "- **追踪与提取**：调用 `src/environment_extractor/pipeline.py::process_nc_files`\n",
        "- **保存到 Drive**：把 `final_single_output/`、`track_single/` 和运行日志复制到 Google Drive\n",
        "\n",
        "建议先用 `MAX_TCS=1` 做小规模验证，再跑全量。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 1) 挂载 Google Drive，并准备仓库路径\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "USE_DRIVE_REPO = True  # True：仓库在 Drive；False：clone 到 /content\n",
        "DRIVE_REPO_PATH = \"/content/drive/MyDrive/TianGong-AI-Cyclone\"\n",
        "REPO_URL = \"https://github.com/wenjie-shi-alpha/TianGong-AI-Cyclone.git\"\n",
        "\n",
        "PROJECT_PATH = DRIVE_REPO_PATH if USE_DRIVE_REPO else \"/content/TianGong-AI-Cyclone\"\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "project = Path(PROJECT_PATH)\n",
        "if USE_DRIVE_REPO and not project.exists():\n",
        "    print(f\"Drive 中未找到仓库目录: {project}，改为 clone 到 /content\")\n",
        "    USE_DRIVE_REPO = False\n",
        "    PROJECT_PATH = \"/content/TianGong-AI-Cyclone\"\n",
        "    project = Path(PROJECT_PATH)\n",
        "\n",
        "if not project.exists():\n",
        "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, str(project)], check=True)\n",
        "\n",
        "os.chdir(PROJECT_PATH)\n",
        "print(\"PROJECT_PATH:\", PROJECT_PATH)\n",
        "print(\"CWD:\", os.getcwd())\n",
        "print(\"Repo files:\", sorted(os.listdir('.'))[:20])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 2) 安装依赖（Colab 环境）\n",
        "# - cfgrib 依赖 ecCodes（系统库 + python 包）\n",
        "# - 其余依赖来自 requirements.txt\n",
        "\n",
        "%%bash\n",
        "set -e\n",
        "apt-get update -qq\n",
        "# 尽量安装 eccodes；不同 Colab 镜像可能包名略有差异，做一个 fallback\n",
        "apt-get install -y -qq libeccodes0 eccodes || apt-get install -y -qq libeccodes0\n",
        "python3 -m pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 3) 设置 PYTHONPATH，确认可导入项目模块\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "SRC_PATH = str(Path(PROJECT_PATH) / \"src\")\n",
        "if SRC_PATH not in sys.path:\n",
        "    sys.path.insert(0, SRC_PATH)\n",
        "\n",
        "from shared.grib_loader import open_grib_collection  # noqa: F401\n",
        "from environment_extractor.pipeline import process_nc_files  # noqa: F401\n",
        "\n",
        "print(\"Import OK. SRC_PATH=\", SRC_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 4) 配置输入与运行参数\n",
        "# 你可以根据自己的数据集/范围修改这些路径与参数\n",
        "\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "GRIB_URLS_CSV = \"output/gfs_grib_urls_00_12_f000_f240_step6.csv\"\n",
        "# 默认使用“剩余待处理”气旋列表（用于断点续跑）\n",
        "TC_TRACKS_CSV = \"input/matched_cyclone_tracks_remaining_from_log.csv\"\n",
        "INITIALS_CSV = \"input/western_pacific_typhoons_superfast.csv\"\n",
        "\n",
        "# 先小跑验证：把 MAX_TCS 设为 1；全量运行时设为 None\n",
        "MAX_TCS = 1\n",
        "\n",
        "# 追踪/提取并行进程数（环境提取会开子进程）\n",
        "PROCESSES = 1\n",
        "\n",
        "# 单个预报周期内，下载 GRIB 的线程数\n",
        "DOWNLOAD_WORKERS = 8\n",
        "\n",
        "# 是否保留中间合并得到的 NC 文件（默认 False，会自动删除以节省空间）\n",
        "KEEP_NC = False\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "if not Path(TC_TRACKS_CSV).exists():\n",
        "    fallback = \"input/matched_cyclone_tracks_2021onwards.csv\"\n",
        "    if Path(fallback).exists():\n",
        "        print(f\"⚠️ 未找到 {TC_TRACKS_CSV}，自动回退到: {fallback}\")\n",
        "        TC_TRACKS_CSV = fallback\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"缺少输入文件: {TC_TRACKS_CSV} 或 {fallback}\")\n",
        "\n",
        "for p in [GRIB_URLS_CSV, TC_TRACKS_CSV, INITIALS_CSV]:\n",
        "    if not Path(p).exists():\n",
        "        raise FileNotFoundError(f\"缺少输入文件: {p}（请确认仓库目录/文件已上传）\")\n",
        "\n",
        "DRIVE_OUTPUT_BASE = Path(\"/content/drive/MyDrive/TianGong-AI-Cyclone_outputs/gfs\")\n",
        "RUN_TAG = datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n",
        "RUN_DIR = DRIVE_OUTPUT_BASE / f\"run_{RUN_TAG}\"\n",
        "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"RUN_DIR:\", RUN_DIR)\n",
        "print(\"MAX_TCS:\", MAX_TCS, \"PROCESSES:\", PROCESSES, \"DOWNLOAD_WORKERS:\", DOWNLOAD_WORKERS, \"KEEP_NC:\", KEEP_NC)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 5) 运行：复用现有脚本 src/process_by_tc_lifetime.py\n",
        "# 输出会写到本地仓库目录（final_single_output/、track_single/），下一步会复制到 Drive。\n",
        "\n",
        "import subprocess\n",
        "\n",
        "cmd = [\n",
        "    \"python3\",\n",
        "    \"src/process_by_tc_lifetime.py\",\n",
        "    \"--grib-urls\",\n",
        "    GRIB_URLS_CSV,\n",
        "    \"--tc-tracks\",\n",
        "    TC_TRACKS_CSV,\n",
        "    \"--initials\",\n",
        "    INITIALS_CSV,\n",
        "    \"--processes\",\n",
        "    str(PROCESSES),\n",
        "    \"--download-workers\",\n",
        "    str(DOWNLOAD_WORKERS),\n",
        "]\n",
        "if MAX_TCS is not None:\n",
        "    cmd += [\"--max-tcs\", str(MAX_TCS)]\n",
        "if KEEP_NC:\n",
        "    cmd += [\"--keep-nc\"]\n",
        "\n",
        "log_path = RUN_DIR / \"process_by_tc_lifetime.log\"\n",
        "print(\"CMD:\", \" \".join(cmd))\n",
        "print(\"LOG:\", log_path)\n",
        "\n",
        "proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
        "with log_path.open(\"w\", encoding=\"utf-8\") as fh:\n",
        "    for line in proc.stdout:\n",
        "        print(line, end=\"\")\n",
        "        fh.write(line)\n",
        "\n",
        "ret = proc.wait()\n",
        "print(\"\\nExit code:\", ret)\n",
        "if ret != 0:\n",
        "    raise RuntimeError(f\"process_by_tc_lifetime.py 运行失败 (exit={ret})，请查看日志: {log_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 6) 将结果复制到 Google Drive（建议只保存最终产物 + 轨迹 + 日志）\n",
        "\n",
        "import shutil\n",
        "\n",
        "def copy_tree(src: Path, dst: Path) -> None:\n",
        "    if not src.exists():\n",
        "        print(\"Skip missing:\", src)\n",
        "        return\n",
        "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "    if src.is_dir():\n",
        "        shutil.copytree(src, dst, dirs_exist_ok=True)\n",
        "    else:\n",
        "        shutil.copy2(src, dst)\n",
        "    print(\"Saved:\", dst)\n",
        "\n",
        "repo_root = Path(PROJECT_PATH)\n",
        "copy_tree(repo_root / \"final_single_output\", RUN_DIR / \"final_single_output\")\n",
        "copy_tree(repo_root / \"track_single\", RUN_DIR / \"track_single\")\n",
        "copy_tree(log_path, RUN_DIR / log_path.name)\n",
        "\n",
        "print(\"\\nDrive output ready:\")\n",
        "print(RUN_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 7) （可选）打包一份 zip，方便下载/分享\n",
        "\n",
        "import shutil\n",
        "\n",
        "zip_path = shutil.make_archive(str(RUN_DIR), \"zip\", root_dir=str(RUN_DIR))\n",
        "print(\"ZIP:\", zip_path)"
      ]
    }
  ]
}
